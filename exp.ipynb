{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(groq_api_key = groq_api_key , model_name = \"Llama3-8b-8192\",temperature=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://python.langchain.com/v0.2/docs/introduction/', 'content': \"LangChain is a framework for developing applications powered by large language models (LLMs). Learn how to use LangChain's open-source libraries, components, and integrations to build, deploy, and evaluate LLM applications and agents.\"}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a framework for developing applications powered by large language models (LLMs).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': 'LangChain is a framework for developing applications powered by large language models (LLMs).'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `run_sqlite_query` with `SELECT COUNT(*) FROM users`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(2000,)]\u001b[0m\u001b[32;1m\u001b[1;3m2000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many users are in the database ?', 'output': '2000'}\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_groq import ChatGroq\n",
    "import sqlite3\n",
    "from langchain.tools import Tool\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize the ChatGroq language model\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"gemma2-9b-It\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"db.sqlite\")\n",
    "\n",
    "def run_sqlite_query(query):\n",
    "    \"\"\"Execute a SQLite query and return the results.\"\"\"\n",
    "    c = conn.cursor()\n",
    "    c.execute(query)\n",
    "    return c.fetchall()\n",
    "\n",
    "# Define the tool for running SQLite queries\n",
    "run_query_tool = Tool.from_function(\n",
    "    name=\"run_sqlite_query\",\n",
    "    description=\"Run a SQLite query.\",\n",
    "    func=run_sqlite_query\n",
    ")\n",
    "\n",
    "# Define the chat prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the agent with the LLM, prompt, and tools\n",
    "agent = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    tools=[run_query_tool]\n",
    ")\n",
    "\n",
    "# Initialize the agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    verbose=True,\n",
    "    tools=[run_query_tool]\n",
    ")\n",
    "\n",
    "# Execute the agent with the input query\n",
    "response = agent_executor.invoke({\"input\": \"How many users are in the database ?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to query the database to get the count of users.\n",
      "\n",
      "Action: run_sqlite_query\n",
      "Action Input: SELECT COUNT(*) FROM users;\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[(2000,)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's the response:\n",
      "\n",
      "Question: How many users are in the database?\n",
      "Thought: I need to query the database to get the count of users.\n",
      "\n",
      "Action: run_sqlite_query\n",
      "Action Input: SELECT COUNT(*) FROM users;\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[(2000,)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I already know the answer from the previous query, so I can just report it.\n",
      "\n",
      "Final Answer: 2000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many users are in the database?', 'output': '2000'}\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_groq import ChatGroq\n",
    "import sqlite3\n",
    "from langchain.tools import Tool\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize the ChatGroq language model\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"Llama3-8b-8192\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"db.sqlite\")\n",
    "\n",
    "def run_sqlite_query(query):\n",
    "    \"\"\"Execute a SQLite query and return the results.\"\"\"\n",
    "    c = conn.cursor()\n",
    "    c.execute(query)\n",
    "    return c.fetchall()\n",
    "\n",
    "# Define the tool for running SQLite queries\n",
    "run_query_tool = Tool.from_function(\n",
    "    name=\"run_sqlite_query\",\n",
    "    description=\"Run a SQLite query.\",\n",
    "    func=run_sqlite_query\n",
    ")\n",
    "\n",
    "# Define the chat prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the agent with the LLM, prompt, and tools\n",
    "agent = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    tools=[run_query_tool]\n",
    ")\n",
    "\n",
    "# Initialize the agent executor\n",
    "agent_executor = initialize_agent(\n",
    "    llm = llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    tools=[run_query_tool]\n",
    ")\n",
    "\n",
    "# Explicit input for the agent\n",
    "input_data = {\"input\": \"How many users are in the database?\"}\n",
    "\n",
    "# Execute the agent with the input query\n",
    "response = agent_executor.invoke({\"input\": \"How many users are in the database?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to retrieve the table names from the database. I can do this by running a query that retrieves the names of all tables in the database.\n",
      "\n",
      "Action: run_sqlite_query\n",
      "Action Input: \"SELECT name FROM sqlite_master WHERE type='table';\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('users',), ('addresses',), ('products',), ('carts',), ('orders',), ('order_products',)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I've retrieved the table names from the database. Now I need to display them in a readable format.\n",
      "\n",
      "Action: None\n",
      "\n",
      "Action Input: None\n",
      "\u001b[0m\n",
      "Observation: None is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mLet's continue.\n",
      "\n",
      "Thought: I need to display the table names in a readable format. I can use the observation from the previous action and print it out.\n",
      "\n",
      "Action: None\n",
      "\n",
      "Action Input: None\n",
      "\u001b[0m\n",
      "Observation: None is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's the continuation:\n",
      "\n",
      "Action: print\n",
      "Action Input: Observation\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mLet's continue.\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's the continuation:\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mLet's continue.\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI see what's going on here!\n",
      "\n",
      "Let's get back on track.\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems like you're stuck! Let's get back on track.\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems like you're having a bit of trouble getting the output you want. Let me help you out!\n",
      "\n",
      "Here's the corrected sequence:\n",
      "\n",
      "Question: please Show the table names in the database\n",
      "Thought: I need to retrieve the table names from the database. I can do this by running a query that retrieves the names of all tables in the database.\n",
      "\n",
      "Action: run_sqlite_query\n",
      "Action Input: \"SELECT name FROM sqlite_master WHERE type='table';\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('users',), ('addresses',), ('products',), ('carts',), ('orders',), ('order_products',)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI'm glad we're getting back on track!\n",
      "\n",
      "Let's continue from where we left off.\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI'm glad we're getting back on track!\n",
      "\n",
      "Let's continue from where we left off.\n",
      "\n",
      "Action: print\n",
      "Action Input: [table_name[0][0] for table_name in Observation]\u001b[0m\n",
      "Observation: print is not a valid tool, try one of [run_sqlite_query].\n",
      "Thought:\u001b[32;1m\u001b[1;3mLet's get back on track.\n",
      "\n",
      "Final Answer: The table names in the database are: users, addresses, products, carts, orders, order_products.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': ' please Show the table names in the databse', 'output': 'The table names in the database are: users, addresses, products, carts, orders, order_products.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"please Show the table names in the databse\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The table names in the database are: users, addresses, products, carts, orders, order_products.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StracturedTool' from 'langchain.tools' (c:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\langchain\\tools\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StracturedTool\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StracturedTool' from 'langchain.tools' (c:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\langchain\\tools\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseSchema' from 'pydantic' (c:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\pydantic\\__init__.cp310-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSchema \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BaseSchema' from 'pydantic' (c:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\pydantic\\__init__.cp310-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseSchema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTool use failed: no tool can be called with name get_user_count\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many users are in the database?', 'output': 'Tool use failed: no tool can be called with name get_user_count'}\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_groq import ChatGroq\n",
    "import sqlite3\n",
    "from langchain.tools import Tool\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "# from langchain_core.tools import InjectedToolArg\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "import os\n",
    "#from langchain_core.tools import InjectedToolArg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize the ChatGroq language model\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"Llama3-8b-8192\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"db.sqlite3\")\n",
    "\n",
    "def run_sqlite_query(query):\n",
    "    \"\"\"Execute a SQLite query and return the results.\"\"\"\n",
    "    c = conn.cursor()\n",
    "    c.execute(query)\n",
    "    return c.fetchall()\n",
    "\n",
    "# Define the tool for running SQLite queries\n",
    "run_query_tool = Tool.from_function(\n",
    "    name=\"run_sqlite_query\",\n",
    "    description=\"Run a SQLite query.\",\n",
    "    func=run_sqlite_query\n",
    ")\n",
    "\n",
    "# Define the chat prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the agent with the LLM, prompt, and tools\n",
    "agent = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    tools=[run_query_tool]\n",
    ")\n",
    "\n",
    "# Initialize the agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    verbose=True,\n",
    "    tools=[run_query_tool]\n",
    ")\n",
    "\n",
    "# Explicit input for the agent\n",
    "input_data = {\"input\": \"How many users are in the database?\"}\n",
    "\n",
    "# Execute the agent with the input query\n",
    "response = agent_executor.invoke(input_data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "\n",
    "from langchain.agents import AgentExecutor ,OpenAIFunctionsAgent\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages = [\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [run_query_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(llm = llm,\n",
    "                             prompt = prompt,\n",
    "                             tools = [run_query_tool]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent = agent ,\n",
    "    Verbose = True ,\n",
    "    tools = [run_query_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many users are in the databse ?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\langchain\\chains\\base.py:135\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m include_run_info \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_run_info\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    133\u001b[0m return_only_outputs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_only_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 135\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[0;32m    137\u001b[0m     callbacks,\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m    144\u001b[0m )\n\u001b[0;32m    145\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\s\\miniconda3\\envs\\langchainenv\\lib\\site-packages\\langchain\\chains\\base.py:510\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;66;03m# If there are multiple input keys, but some get set by memory so that\u001b[39;00m\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;66;03m# only one is not set, we can still figure out which key it is.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m         _input_keys \u001b[38;5;241m=\u001b[39m _input_keys\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmemory_variables)\n\u001b[1;32m--> 510\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_input_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m: inputs}\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     external_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mload_memory_variables(inputs)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "In LangChain, callbacks and callback handlers are mechanisms that allow you to track, log, and manipulate the execution flow of chains, agents, and models. These tools are particularly useful for debugging, logging, monitoring, and customizing the behavior of your language models or other components in the LangChain framework.\n",
    "\n",
    "1. What is a Callback?\n",
    "A callback is essentially a function or a set of functions that gets called at specific points during the execution of a chain, agent, or model. These points can include:\n",
    "\n",
    "Before an action is taken (e.g., before a tool is invoked).\n",
    "After an action is taken (e.g., after a tool returns a result).\n",
    "On error (e.g., when an error occurs during execution).\n",
    "On chain start or end (e.g., when a chain begins or finishes processing).\n",
    "2. What is a Callback Handler?\n",
    "A callback handler is an object that contains one or more callback functions. LangChain uses these handlers to manage and trigger callbacks during execution. You can attach multiple callback handlers to a chain or agent, and each handler can define custom logic for each of the possible callback events.\n",
    "\n",
    "3. Why Use Callbacks and Callback Handlers?\n",
    "Callbacks and callback handlers allow you to:\n",
    "\n",
    "Monitor Execution: Log inputs, outputs, and intermediate steps.\n",
    "Debug: Track where things go wrong during execution.\n",
    "Modify Behavior: Adjust the execution flow based on specific conditions.\n",
    "Track Performance: Measure the time taken by different parts of the chain or agent.\n",
    "4. Examples\n",
    "Basic Example: Logging with a Callback Handler\n",
    "Suppose you want to log the start and end of a chain's execution:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from langchain.callbacks import BaseCallbackHandler\n",
    "\n",
    "class MyLoggingCallbackHandler(BaseCallbackHandler):\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        print(f\"Chain started with inputs: {inputs}\")\n",
    "\n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        print(f\"Chain ended with outputs: {outputs}\")\n",
    "\n",
    "# Initialize your handler\n",
    "my_logging_handler = MyLoggingCallbackHandler()\n",
    "\n",
    "# Attach the handler to a chain or agent\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    verbose=True,\n",
    "    tools=[run_query_tool],\n",
    "    callbacks=[my_logging_handler]  # Attach the callback handler here\n",
    ")\n",
    "\n",
    "# Execute the agent with the input query\n",
    "response = agent_executor.invoke({\"input\": \"How many users are in the database?\"})\n",
    "This will print logs when the chain starts and ends, making it easier to follow the flow of execution.\n",
    "\n",
    "Advanced Example: Timing Execution Steps\n",
    "If you want to measure how long each part of the chain or agent takes to execute:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import time\n",
    "from langchain.callbacks import BaseCallbackHandler\n",
    "\n",
    "class TimingCallbackHandler(BaseCallbackHandler):\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        self.start_time = time.time()\n",
    "        print(\"Chain started.\")\n",
    "\n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - self.start_time\n",
    "        print(f\"Chain ended. Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Initialize your handler\n",
    "timing_handler = TimingCallbackHandler()\n",
    "\n",
    "# Attach the handler to a chain or agent\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    verbose=True,\n",
    "    tools=[run_query_tool],\n",
    "    callbacks=[timing_handler]  # Attach the callback handler here\n",
    ")\n",
    "\n",
    "# Execute the agent with the input query\n",
    "response = agent_executor.invoke({\"input\": \"How many users are in the database?\"})\n",
    "This callback handler will measure and print how long the entire chain or agent took to execute.\n",
    "\n",
    "5. Built-in Callback Handlers\n",
    "LangChain provides some built-in callback handlers, such as:\n",
    "\n",
    "StreamingStdOutCallbackHandler: Streams output to standard output.\n",
    "AsyncCallbackHandler: Handles callbacks asynchronously.\n",
    "TracingCallbackHandler: Integrates with tracing systems to monitor execution.\n",
    "You can also create your custom callback handlers by subclassing BaseCallbackHandler.\n",
    "\n",
    "6. Using Multiple Callback Handlers\n",
    "You can attach multiple callback handlers to a single chain or agent. Each handler will be invoked according to the events it subscribes to. This is useful for combining different types of monitoring and logging behaviors.\n",
    "\n",
    "Conclusion\n",
    "Callbacks and callback handlers in LangChain are powerful tools for managing and customizing the execution of chains and agents. They offer a way to insert custom logic at different stages of the execution process, making it easier to debug, log, and control the behavior of your applications.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
